{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1975ad-e2f2-46f6-9afe-cfe3f8ce7839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (1.57.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai) (0.28.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/opt/certifi/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46c190e-4c51-445f-a352-9a59228772ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a949ae52-f2e9-4dc4-8e52-4b688ba49ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.55.3 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from langchain-openai) (1.57.1)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (6.0.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.21->langchain-openai)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.3,>=0.1.125 (from langchain-core<0.4.0,>=0.3.21->langchain-openai)\n",
      "  Downloading langsmith-0.2.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (2.10.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<0.4.0,>=0.3.21->langchain-openai)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (0.28.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.55.3->langchain-openai) (4.67.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/opt/certifi/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai) (3.0.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai)\n",
      "  Downloading orjson-3.10.12-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain-openai)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai) (2.27.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
      "Downloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
      "Downloading tiktoken-0.8.0-cp313-cp313-macosx_11_0_arm64.whl (982 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.8/982.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.2.2-py3-none-any.whl (320 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading orjson-3.10.12-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: tenacity, regex, orjson, jsonpatch, tiktoken, requests-toolbelt, langsmith, langchain-core, langchain-openai\n",
      "Successfully installed jsonpatch-1.33 langchain-core-0.3.24 langchain-openai-0.2.12 langsmith-0.2.2 orjson-3.10.12 regex-2024.11.6 requests-toolbelt-1.0.0 tenacity-9.0.0 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712f7154-b8d2-4382-9d44-087ea560954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af6945fe-4dbe-4d6f-a500-c828da6a1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm(model=\"gpt-4o\"):\n",
    "   llm = ChatOpenAI(model=model,\n",
    "   temperature=0,\n",
    "   max_tokens=None,\n",
    "   timeout=None,\n",
    "   max_retries=2)\n",
    "   llm.bind(response_format={\"type\": \"json_object\"})\n",
    "   return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f00290a-76a4-4fd8-ad33-2d8f0bed1f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An AI agent, in simple terms, is like a smart computer program that can make decisions and perform tasks on its own. Imagine it as a virtual assistant that can understand what you want, think about the best way to help you, and then do it without needing you to guide it every step of the way. For example, an AI agent could be a chatbot that answers your questions online, a virtual assistant like Siri or Alexa that helps you with tasks on your phone, or even a program that plays games against you. It uses artificial intelligence to learn from its experiences and improve over time, just like how people learn from practice.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llm().invoke(\"Explain what is Ai Agent in layman terms\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2b0197b-804c-4ee7-aedf-bb0d3f39d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"Translate the text {text} to {language} and just give me the translated text as output\")\n",
    "])\n",
    "chain = prompt | get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9612189-40c9-4d57-86c2-8064e6340606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comment ça va ?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": \"How are you\", \"language\":\"French\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea8d176e-a8cc-4c74-a825-c9a1f32a4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0a6d394-373c-4787-8580-33df71f2c431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "review_prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(review_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f64dcd84-2736-40d5-942a-cb0accea7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = review_prompt_template | get_llm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c82bc6a-b5a0-4abb-b7af-ed6d649f5483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"gift\": true,\\n  \"delivery_days\": 2,\\n  \"price_value\": [\\n    \"It\\'s slightly more expensive than the other leaf blowers out there, but I think it\\'s worth it for the extra features.\"\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_chain.invoke({\"text\":customer_review}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7113845-9dd0-4be4-847e-1a0925cb7b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
